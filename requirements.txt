fastapi==0.104.1
uvicorn[standard]==0.24.0
llama-cpp-python>=0.2.0
huggingface-hub>=0.20.0
requests>=2.31.0

